{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_handwritten_digit_recognition.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kushagrabansal/Handwritten_Digit_Recognition/blob/master/MNIST_handwritten_digit_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G92ZBtm6RJql",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "#-----------------------------------------------\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split # splitting dataset\n",
        "\n",
        "#-----------------------tensorflow--------\n",
        "import tensorflow as tf\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoZmU0OKWeY4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('train.csv')\n",
        "data.head(420)\n",
        "\n",
        "labels_flat=data.iloc[:,0].values\n",
        "images=data.iloc[:,1:].values\n",
        "one_hot_encoder=OneHotEncoder(sparse=False) \n",
        "encoded=labels_flat.reshape(len(labels_flat),1)#creates an array of 42000individual x 1\n",
        "labels=one_hot_encoder.fit_transform(encoded) # categorial data into encode vector\n",
        "labels=labels.astype(np.uint8) \n",
        "\n",
        "xtrain,xval,ytrain,yval=train_test_split(images, labels, test_size=0.2, random_state=0)\n",
        "\n",
        "X=tf.placeholder(tf.float32,[None,784],name='Input') # placeholders<dattype,shape,name>\n",
        "Y=tf.placeholder(tf.float32,[None,10],name='Output') # None because don't know the no of images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koZ23F4SWitg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights_1=tf.Variable(tf.truncated_normal([784, 120],stddev=0.001),name='weights_1')\n",
        "biases_1=tf.Variable(tf.zeros([120]),name='biases_1')\n",
        "hidden1=tf.nn.relu(tf.matmul(X,weights_1)+biases_1)\n",
        "\n",
        "weights_2=tf.Variable(tf.truncated_normal([120, 32],stddev=0.001),name='weights_2')\n",
        "biases_2=tf.Variable(tf.zeros([32]),name='biases_2')\n",
        "hidden2=tf.nn.relu(tf.matmul(hidden1,weights_2)+biases_2)\n",
        "\n",
        "weights_3=tf.Variable(tf.zeros([32, 10]),name='weights_3')\n",
        "biases_3=tf.Variable(tf.zeros([10]),name='biases_3')\n",
        "Ylogits=tf.matmul(hidden2,weights_3)+biases_3\n",
        "output=tf.nn.softmax(Ylogits) # for output : softmax activation function\n",
        "\n",
        "#cross_entropy difference bw actual and predicted value\n",
        "cross_entropy=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=Ylogits,labels=Y))\n",
        "optimizer=tf.train.GradientDescentOptimizer(0.005) #gradient descent optimizer learning rate alpha=0.005\n",
        "train_step=optimizer.minimize(cross_entropy) # GD optimizer help us to minimize loss\n",
        "\n",
        "# correct pred is used to find which predictions are correct and which predictions are wrong\n",
        "correct_prediction=tf.equal(tf.argmax(output,1),tf.argmax(Y,1))\n",
        "#argmax() it pick up the index of maximum value in array\n",
        "#output is an array of probability and it picks the index of highest prob\n",
        "# equal fuction compares the value of both the arrays\n",
        "\n",
        "accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
        "# calculates accuracy\n",
        "# cast convert it to float datatype\n",
        "# reduce_min to get the mean or avg value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqG_AN6UWnIy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.Session() as sess:\n",
        "  init=tf.global_variables_initializer()\n",
        "  sess.run(init)\n",
        "  \n",
        "  batch_size=200 # no of images pass to the neural network {none-->batch_size}\n",
        "  epoch=100 # how many times training data pass through the neural network\n",
        "  iterations=int(xtrain.shape[0]/batch_size) \n",
        "  \n",
        "  for ep in range(epoch):\n",
        "    for i in range(iterations):\n",
        "      batch_start=(i*batch_size)%(xtrain.shape[0]-batch_size)\n",
        "      batch_end=batch_start + batch_size\n",
        "      batch_X=xtrain[batch_start:batch_end]\n",
        "      batch_Y=ytrain[batch_start:batch_end]\n",
        "      train_data={X:batch_X,Y:batch_Y}\n",
        "      \n",
        "      sess.run(train_step, feed_dict=train_data)\n",
        "    ans=sess.run(accuracy,feed_dict={X:xval,Y:yval})\n",
        "    print(\"EPOCH NUMBER \"+str(ep+1)+\" |\",\"Accurracy : {} %\".format(ans*100))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}